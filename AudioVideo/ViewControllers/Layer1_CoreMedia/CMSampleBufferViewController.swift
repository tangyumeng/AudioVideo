//
//  CMSampleBufferViewController.swift
//  AudioVideo
//
//  Layer 1: Core Media & Core Video
//  CMSampleBuffer æ˜¯è§†é¢‘å¸§çš„æ ¸å¿ƒå®¹å™¨
//

import UIKit
import AVFoundation
import CoreMedia

class CMSampleBufferViewController: UIViewController {
    
    // MARK: - Properties
    
    private var captureSession: AVCaptureSession?
    private var videoOutput: AVCaptureVideoDataOutput?
    private var previewLayer: AVCaptureVideoPreviewLayer?
    
    private let infoTextView: UITextView = {
        let textView = UITextView()
        textView.isEditable = false
        textView.font = .monospacedSystemFont(ofSize: 12, weight: .regular)
        textView.backgroundColor = .systemBackground
        textView.textColor = .label
        textView.layer.borderWidth = 1
        textView.layer.borderColor = UIColor.systemGray4.cgColor
        textView.layer.cornerRadius = 8
        textView.translatesAutoresizingMaskIntoConstraints = false
        return textView
    }()
    
    private let previewView: UIView = {
        let view = UIView()
        view.backgroundColor = .black
        view.layer.cornerRadius = 8
        view.clipsToBounds = true
        view.translatesAutoresizingMaskIntoConstraints = false
        return view
    }()
    
    private let startButton: UIButton = {
        let button = UIButton(type: .system)
        button.setTitle("å¼€å§‹é‡‡é›†", for: .normal)
        button.backgroundColor = .systemBlue
        button.setTitleColor(.white, for: .normal)
        button.layer.cornerRadius = 8
        button.translatesAutoresizingMaskIntoConstraints = false
        return button
    }()
    
    private let scrollView: UIScrollView = {
        let scroll = UIScrollView()
        scroll.translatesAutoresizingMaskIntoConstraints = false
        return scroll
    }()
    
    private let contentView: UIView = {
        let view = UIView()
        view.translatesAutoresizingMaskIntoConstraints = false
        return view
    }()
    
    private let descriptionLabel: UILabel = {
        let label = UILabel()
        label.numberOfLines = 0
        label.font = .systemFont(ofSize: 14)
        label.textColor = .secondaryLabel
        label.text = """
        ğŸ“¦ CMSampleBuffer è¯¦è§£
        
        CMSampleBuffer æ˜¯ Core Media æ¡†æ¶ä¸­æœ€æ ¸å¿ƒçš„æ•°æ®ç»“æ„ï¼Œå®ƒå°è£…äº†åª’ä½“æ•°æ®ï¼ˆå¦‚è§†é¢‘å¸§æˆ–éŸ³é¢‘æ ·æœ¬ï¼‰ä»¥åŠç›¸å…³çš„å…ƒæ•°æ®ã€‚
        
        æ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼š
        â€¢ CVImageBuffer (CVPixelBuffer): å®é™…çš„åƒç´ æ•°æ®
        â€¢ CMTime: ç²¾ç¡®çš„æ—¶é—´æˆ³ä¿¡æ¯
        â€¢ CMFormatDescription: æ ¼å¼æè¿°ï¼ˆåˆ†è¾¨ç‡ã€é¢œè‰²ç©ºé—´ç­‰ï¼‰
        â€¢ CMAttachments: é™„åŠ ä¿¡æ¯ï¼ˆæ›å…‰æ—¶é—´ã€ISOç­‰ï¼‰
        
        ä¸‹é¢çš„å®æ—¶ä¿¡æ¯å±•ç¤ºäº†æ¯ä¸€å¸§çš„è¯¦ç»†æ•°æ®ï¼š
        """
        label.translatesAutoresizingMaskIntoConstraints = false
        return label
    }()
    
    // MARK: - Lifecycle
    
    override func viewDidLoad() {
        super.viewDidLoad()
        setupUI()
        setupActions()
        requestCameraPermission()
    }
    
    override func viewDidLayoutSubviews() {
        super.viewDidLayoutSubviews()
        previewLayer?.frame = previewView.bounds
    }
    
    deinit {
        captureSession?.stopRunning()
    }
    
    // MARK: - Setup
    
    private func setupUI() {
        view.backgroundColor = .systemBackground
        
        view.addSubview(scrollView)
        scrollView.addSubview(contentView)
        
        contentView.addSubview(descriptionLabel)
        contentView.addSubview(startButton)
        contentView.addSubview(previewView)
        contentView.addSubview(infoTextView)
        
        NSLayoutConstraint.activate([
            scrollView.topAnchor.constraint(equalTo: view.safeAreaLayoutGuide.topAnchor),
            scrollView.leadingAnchor.constraint(equalTo: view.leadingAnchor),
            scrollView.trailingAnchor.constraint(equalTo: view.trailingAnchor),
            scrollView.bottomAnchor.constraint(equalTo: view.bottomAnchor),
            
            contentView.topAnchor.constraint(equalTo: scrollView.topAnchor),
            contentView.leadingAnchor.constraint(equalTo: scrollView.leadingAnchor),
            contentView.trailingAnchor.constraint(equalTo: scrollView.trailingAnchor),
            contentView.bottomAnchor.constraint(equalTo: scrollView.bottomAnchor),
            contentView.widthAnchor.constraint(equalTo: scrollView.widthAnchor),
            
            descriptionLabel.topAnchor.constraint(equalTo: contentView.topAnchor, constant: 16),
            descriptionLabel.leadingAnchor.constraint(equalTo: contentView.leadingAnchor, constant: 16),
            descriptionLabel.trailingAnchor.constraint(equalTo: contentView.trailingAnchor, constant: -16),
            
            startButton.topAnchor.constraint(equalTo: descriptionLabel.bottomAnchor, constant: 16),
            startButton.centerXAnchor.constraint(equalTo: contentView.centerXAnchor),
            startButton.widthAnchor.constraint(equalToConstant: 120),
            startButton.heightAnchor.constraint(equalToConstant: 44),
            
            previewView.topAnchor.constraint(equalTo: startButton.bottomAnchor, constant: 16),
            previewView.leadingAnchor.constraint(equalTo: contentView.leadingAnchor, constant: 16),
            previewView.trailingAnchor.constraint(equalTo: contentView.trailingAnchor, constant: -16),
            previewView.heightAnchor.constraint(equalTo: previewView.widthAnchor, multiplier: 4.0/3.0),
            
            infoTextView.topAnchor.constraint(equalTo: previewView.bottomAnchor, constant: 16),
            infoTextView.leadingAnchor.constraint(equalTo: contentView.leadingAnchor, constant: 16),
            infoTextView.trailingAnchor.constraint(equalTo: contentView.trailingAnchor, constant: -16),
            infoTextView.heightAnchor.constraint(equalToConstant: 400),
            infoTextView.bottomAnchor.constraint(equalTo: contentView.bottomAnchor, constant: -16)
        ])
    }
    
    private func setupActions() {
        startButton.addTarget(self, action: #selector(toggleCapture), for: .touchUpInside)
    }
    
    // MARK: - Camera Permission
    
    private func requestCameraPermission() {
        switch AVCaptureDevice.authorizationStatus(for: .video) {
        case .authorized:
            break
        case .notDetermined:
            AVCaptureDevice.requestAccess(for: .video) { granted in
                if granted {
                    print("Camera permission granted")
                }
            }
        case .denied, .restricted:
            showAlert(title: "ç›¸æœºæƒé™", message: "è¯·åœ¨è®¾ç½®ä¸­å¼€å¯ç›¸æœºæƒé™")
        @unknown default:
            break
        }
    }
    
    // MARK: - Actions
    
    @objc private func toggleCapture() {
        if captureSession?.isRunning == true {
            // åœ¨åå°çº¿ç¨‹åœæ­¢session
            DispatchQueue.global(qos: .userInitiated).async { [weak self] in
                self?.captureSession?.stopRunning()
                
                // æ›´æ–°UIéœ€è¦å›åˆ°ä¸»çº¿ç¨‹
                DispatchQueue.main.async {
                    self?.startButton.setTitle("å¼€å§‹é‡‡é›†", for: .normal)
                    self?.startButton.backgroundColor = .systemBlue
                }
            }
        } else {
            if captureSession == nil {
                setupCaptureSession()
            }
            
            // åœ¨åå°çº¿ç¨‹å¯åŠ¨session
            DispatchQueue.global(qos: .userInitiated).async { [weak self] in
                self?.captureSession?.startRunning()
                
                // æ›´æ–°UIéœ€è¦å›åˆ°ä¸»çº¿ç¨‹
                DispatchQueue.main.async {
                    self?.startButton.setTitle("åœæ­¢é‡‡é›†", for: .normal)
                    self?.startButton.backgroundColor = .systemRed
                }
            }
        }
    }
    
    // MARK: - Capture Setup
    
    private func setupCaptureSession() {
        captureSession = AVCaptureSession()
        captureSession?.sessionPreset = .vga640x480
        
        // è®¾ç½®æ‘„åƒå¤´è¾“å…¥
        guard let camera = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .front),
              let input = try? AVCaptureDeviceInput(device: camera) else {
            showAlert(title: "é”™è¯¯", message: "æ— æ³•è®¿é—®æ‘„åƒå¤´")
            return
        }
        
        if captureSession?.canAddInput(input) == true {
            captureSession?.addInput(input)
        }
        
        // è®¾ç½®è§†é¢‘æ•°æ®è¾“å‡º
        videoOutput = AVCaptureVideoDataOutput()
        videoOutput?.videoSettings = [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA
        ]
        
        let queue = DispatchQueue(label: "com.audiovideo.videoqueue")
        videoOutput?.setSampleBufferDelegate(self, queue: queue)
        videoOutput?.alwaysDiscardsLateVideoFrames = true
        
        if let output = videoOutput, captureSession?.canAddOutput(output) == true {
            captureSession?.addOutput(output)
        }
        
        // è®¾ç½®é¢„è§ˆå›¾å±‚
        let preview = AVCaptureVideoPreviewLayer(session: captureSession!)
        preview.videoGravity = .resizeAspectFill
        preview.frame = previewView.bounds
        previewView.layer.addSublayer(preview)
        previewLayer = preview
    }
    
    // MARK: - CMSampleBuffer Analysis
    
    private func analyzeSampleBuffer(_ sampleBuffer: CMSampleBuffer) -> String {
        var info = "â•”â•â•â• CMSampleBuffer åˆ†æ â•â•â•â•—\n\n"
        
        // 1. æ—¶é—´ä¿¡æ¯
        info += "â± æ—¶é—´ä¿¡æ¯ (CMTime)\n"
        let presentationTime = CMSampleBufferGetPresentationTimeStamp(sampleBuffer)
        info += "  â€¢ PTS (Presentation Time): \(presentationTime.seconds)s\n"
        info += "  â€¢ Time Value: \(presentationTime.value)\n"
        info += "  â€¢ Time Scale: \(presentationTime.timescale)\n"
        info += "  â€¢ Flags: \(presentationTime.flags)\n"
        
        let duration = CMSampleBufferGetDuration(sampleBuffer)
        if duration.isValid {
            info += "  â€¢ Duration: \(duration.seconds)s\n"
        }
        
        info += "\n"
        
        // 2. æ ¼å¼æè¿°
        if let formatDesc = CMSampleBufferGetFormatDescription(sampleBuffer) {
            info += "ğŸ“ æ ¼å¼æè¿° (CMFormatDescription)\n"
            
            let mediaType = CMFormatDescriptionGetMediaType(formatDesc)
            info += "  â€¢ Media Type: \(fourCCToString(mediaType))\n"
            
            let mediaSubtype = CMFormatDescriptionGetMediaSubType(formatDesc)
            info += "  â€¢ Media Subtype: \(fourCCToString(mediaSubtype))\n"
            
            let dimensions = CMVideoFormatDescriptionGetDimensions(formatDesc)
            info += "  â€¢ Dimensions: \(dimensions.width) x \(dimensions.height)\n"
            
            if let extensions = CMFormatDescriptionGetExtensions(formatDesc) as? [String: Any] {
                info += "  â€¢ Extensions: \(extensions.count) items\n"
            }
        }
        
        info += "\n"
        
        // 3. åƒç´ ç¼“å†²åŒº
        if let imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) {
            info += "ğŸ–¼ åƒç´ ç¼“å†²åŒº (CVPixelBuffer)\n"
            
            let width = CVPixelBufferGetWidth(imageBuffer)
            let height = CVPixelBufferGetHeight(imageBuffer)
            info += "  â€¢ Size: \(width) x \(height)\n"
            
            let pixelFormat = CVPixelBufferGetPixelFormatType(imageBuffer)
            info += "  â€¢ Pixel Format: \(fourCCToString(pixelFormat))\n"
            
            let bytesPerRow = CVPixelBufferGetBytesPerRow(imageBuffer)
            info += "  â€¢ Bytes Per Row: \(bytesPerRow)\n"
            
            let dataSize = CVPixelBufferGetDataSize(imageBuffer)
            info += "  â€¢ Data Size: \(formatBytes(dataSize))\n"
            
            let planeCount = CVPixelBufferGetPlaneCount(imageBuffer)
            info += "  â€¢ Plane Count: \(planeCount)\n"
            
            // æ£€æŸ¥æ˜¯å¦ä¸ºå¹³é¢æ ¼å¼ï¼ˆå¦‚YUVï¼‰
            if planeCount > 0 {
                info += "  â€¢ Planar Format:\n"
                for i in 0..<planeCount {
                    let planeWidth = CVPixelBufferGetWidthOfPlane(imageBuffer, i)
                    let planeHeight = CVPixelBufferGetHeightOfPlane(imageBuffer, i)
                    let planeBytesPerRow = CVPixelBufferGetBytesPerRowOfPlane(imageBuffer, i)
                    info += "    - Plane \(i): \(planeWidth)x\(planeHeight), \(planeBytesPerRow) bytes/row\n"
                }
            }
        }
        
        info += "\n"
        
        // 4. é™„ä»¶ä¿¡æ¯ï¼ˆAttachmentsï¼‰
        if let attachments = CMSampleBufferGetSampleAttachmentsArray(sampleBuffer, createIfNecessary: false) as? [[String: Any]] {
            info += "ğŸ“ é™„ä»¶ä¿¡æ¯ (Attachments)\n"
            if let firstAttachment = attachments.first {
                for (key, value) in firstAttachment {
                    info += "  â€¢ \(key): \(value)\n"
                }
            }
        }
        
        info += "\n"
        
        // 5. æ•°æ®å°±ç»ªçŠ¶æ€
        info += "âœ… çŠ¶æ€ä¿¡æ¯\n"
        let dataReady = CMSampleBufferDataIsReady(sampleBuffer)
        info += "  â€¢ Data Ready: \(dataReady)\n"
        
        let numSamples = CMSampleBufferGetNumSamples(sampleBuffer)
        info += "  â€¢ Num Samples: \(numSamples)\n"
        
        let totalSize = CMSampleBufferGetTotalSampleSize(sampleBuffer)
        info += "  â€¢ Total Size: \(formatBytes(totalSize))\n"
        
        info += "\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        
        return info
    }
    
    // MARK: - Helper Methods
    
    private func fourCCToString(_ value: FourCharCode) -> String {
        let chars = [
            Character(UnicodeScalar((value >> 24) & 0xFF)!),
            Character(UnicodeScalar((value >> 16) & 0xFF)!),
            Character(UnicodeScalar((value >> 8) & 0xFF)!),
            Character(UnicodeScalar(value & 0xFF)!)
        ]
        return String(chars)
    }
    
    private func formatBytes(_ bytes: Int) -> String {
        let formatter = ByteCountFormatter()
        formatter.countStyle = .binary
        return formatter.string(fromByteCount: Int64(bytes))
    }
    
    private func showAlert(title: String, message: String) {
        DispatchQueue.main.async {
            let alert = UIAlertController(title: title, message: message, preferredStyle: .alert)
            alert.addAction(UIAlertAction(title: "ç¡®å®š", style: .default))
            self.present(alert, animated: true)
        }
    }
}

// MARK: - AVCaptureVideoDataOutputSampleBufferDelegate

extension CMSampleBufferViewController: AVCaptureVideoDataOutputSampleBufferDelegate {
    func captureOutput(_ output: AVCaptureOutput,
                      didOutput sampleBuffer: CMSampleBuffer,
                      from connection: AVCaptureConnection) {
        // åˆ†æ CMSampleBuffer
        let info = analyzeSampleBuffer(sampleBuffer)
        
        // æ›´æ–°UIï¼ˆé™åˆ¶æ›´æ–°é¢‘ç‡ï¼‰
        DispatchQueue.main.async { [weak self] in
            self?.infoTextView.text = info
        }
    }
}

