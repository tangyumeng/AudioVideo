//
//  CVPixelBufferViewController.swift
//  AudioVideo
//
//  Layer 1: Core Media & Core Video
//  CVPixelBuffer ç›´æ¥æ“ä½œåƒç´ æ•°æ®
//

import UIKit
import AVFoundation
import CoreVideo
import Accelerate

class CVPixelBufferViewController: UIViewController {
    
    // MARK: - Properties
    
    private var captureSession: AVCaptureSession?
    private var videoOutput: AVCaptureVideoDataOutput?
    
    // å½“å‰å¤„ç†æ¨¡å¼ï¼ˆçº¿ç¨‹å®‰å…¨çš„å±æ€§ï¼‰
    private var currentProcessMode: Int = 0
    
    private let originalImageView: UIImageView = {
        let imageView = UIImageView()
        imageView.contentMode = .scaleAspectFit
        imageView.backgroundColor = .black
        imageView.layer.cornerRadius = 8
        imageView.clipsToBounds = true
        imageView.translatesAutoresizingMaskIntoConstraints = false
        return imageView
    }()
    
    private let processedImageView: UIImageView = {
        let imageView = UIImageView()
        imageView.contentMode = .scaleAspectFit
        imageView.backgroundColor = .black
        imageView.layer.cornerRadius = 8
        imageView.clipsToBounds = true
        imageView.translatesAutoresizingMaskIntoConstraints = false
        return imageView
    }()
    
    private let infoLabel: UILabel = {
        let label = UILabel()
        label.numberOfLines = 0
        label.font = .monospacedSystemFont(ofSize: 11, weight: .regular)
        label.textAlignment = .center
        label.translatesAutoresizingMaskIntoConstraints = false
        return label
    }()
    
    private let startButton: UIButton = {
        let button = UIButton(type: .system)
        button.setTitle("å¼€å§‹å¤„ç†", for: .normal)
        button.backgroundColor = .systemBlue
        button.setTitleColor(.white, for: .normal)
        button.layer.cornerRadius = 8
        button.translatesAutoresizingMaskIntoConstraints = false
        return button
    }()
    
    private let processModeSegment: UISegmentedControl = {
        let items = ["ç°åº¦", "åè‰²", "äº®åº¦", "åƒç´ è¯»å–"]
        let segment = UISegmentedControl(items: items)
        segment.selectedSegmentIndex = 0
        segment.translatesAutoresizingMaskIntoConstraints = false
        return segment
    }()
    
    private let scrollView: UIScrollView = {
        let scroll = UIScrollView()
        scroll.translatesAutoresizingMaskIntoConstraints = false
        return scroll
    }()
    
    private let contentView: UIView = {
        let view = UIView()
        view.translatesAutoresizingMaskIntoConstraints = false
        return view
    }()
    
    private let descriptionLabel: UILabel = {
        let label = UILabel()
        label.numberOfLines = 0
        label.font = .systemFont(ofSize: 14)
        label.textColor = .secondaryLabel
        label.text = """
        ğŸ–¼ CVPixelBuffer ç›´æ¥æ“ä½œ
        
        CVPixelBuffer æ˜¯ Core Video ä¸­ç”¨äºå­˜å‚¨åƒç´ æ•°æ®çš„æ ¸å¿ƒç»“æ„ã€‚å®ƒæä¾›äº†ï¼š
        â€¢ ç›´æ¥è®¿é—®åƒç´ æ•°æ®çš„èƒ½åŠ›
        â€¢ é«˜æ•ˆçš„å†…å­˜ç®¡ç†ï¼ˆIOSurfaceæ”¯æŒï¼‰
        â€¢ GPUå’ŒCPUä¹‹é—´çš„é›¶æ‹·è´ä¼ è¾“
        
        ä¸‹é¢æ¼”ç¤ºäº†å‡ ç§å¸¸è§çš„åƒç´ æ“ä½œï¼š
        1. ç°åº¦è½¬æ¢ - å°†RGBè½¬ä¸ºç°åº¦
        2. åè‰²æ•ˆæœ - åè½¬æ‰€æœ‰é¢œè‰²
        3. äº®åº¦è°ƒæ•´ - å¢åŠ æˆ–å‡å°‘äº®åº¦
        4. åƒç´ è¯»å– - ç›´æ¥è¯»å–åƒç´ å€¼
        """
        label.translatesAutoresizingMaskIntoConstraints = false
        return label
    }()
    
    // MARK: - Lifecycle
    
    override func viewDidLoad() {
        super.viewDidLoad()
        setupUI()
        setupActions()
        requestCameraPermission()
    }
    
    deinit {
        captureSession?.stopRunning()
    }
    
    // MARK: - Setup
    
    private func setupUI() {
        view.backgroundColor = .systemBackground
        
        view.addSubview(scrollView)
        scrollView.addSubview(contentView)
        
        contentView.addSubview(descriptionLabel)
        contentView.addSubview(processModeSegment)
        contentView.addSubview(startButton)
        
        let stackView = UIStackView(arrangedSubviews: [
            createLabeledView(title: "åŸå§‹ç”»é¢", view: originalImageView),
            createLabeledView(title: "å¤„ç†åç”»é¢", view: processedImageView)
        ])
        stackView.axis = .vertical
        stackView.spacing = 16
        stackView.translatesAutoresizingMaskIntoConstraints = false
        contentView.addSubview(stackView)
        
        contentView.addSubview(infoLabel)
        
        NSLayoutConstraint.activate([
            scrollView.topAnchor.constraint(equalTo: view.safeAreaLayoutGuide.topAnchor),
            scrollView.leadingAnchor.constraint(equalTo: view.leadingAnchor),
            scrollView.trailingAnchor.constraint(equalTo: view.trailingAnchor),
            scrollView.bottomAnchor.constraint(equalTo: view.bottomAnchor),
            
            contentView.topAnchor.constraint(equalTo: scrollView.topAnchor),
            contentView.leadingAnchor.constraint(equalTo: scrollView.leadingAnchor),
            contentView.trailingAnchor.constraint(equalTo: scrollView.trailingAnchor),
            contentView.bottomAnchor.constraint(equalTo: scrollView.bottomAnchor),
            contentView.widthAnchor.constraint(equalTo: scrollView.widthAnchor),
            
            descriptionLabel.topAnchor.constraint(equalTo: contentView.topAnchor, constant: 16),
            descriptionLabel.leadingAnchor.constraint(equalTo: contentView.leadingAnchor, constant: 16),
            descriptionLabel.trailingAnchor.constraint(equalTo: contentView.trailingAnchor, constant: -16),
            
            processModeSegment.topAnchor.constraint(equalTo: descriptionLabel.bottomAnchor, constant: 16),
            processModeSegment.leadingAnchor.constraint(equalTo: contentView.leadingAnchor, constant: 16),
            processModeSegment.trailingAnchor.constraint(equalTo: contentView.trailingAnchor, constant: -16),
            
            startButton.topAnchor.constraint(equalTo: processModeSegment.bottomAnchor, constant: 16),
            startButton.centerXAnchor.constraint(equalTo: contentView.centerXAnchor),
            startButton.widthAnchor.constraint(equalToConstant: 120),
            startButton.heightAnchor.constraint(equalToConstant: 44),
            
            stackView.topAnchor.constraint(equalTo: startButton.bottomAnchor, constant: 16),
            stackView.leadingAnchor.constraint(equalTo: contentView.leadingAnchor, constant: 16),
            stackView.trailingAnchor.constraint(equalTo: contentView.trailingAnchor, constant: -16),
            
            originalImageView.heightAnchor.constraint(equalToConstant: 200),
            processedImageView.heightAnchor.constraint(equalToConstant: 200),
            
            infoLabel.topAnchor.constraint(equalTo: stackView.bottomAnchor, constant: 16),
            infoLabel.leadingAnchor.constraint(equalTo: contentView.leadingAnchor, constant: 16),
            infoLabel.trailingAnchor.constraint(equalTo: contentView.trailingAnchor, constant: -16),
            infoLabel.bottomAnchor.constraint(equalTo: contentView.bottomAnchor, constant: -16)
        ])
    }
    
    private func createLabeledView(title: String, view: UIView) -> UIView {
        let container = UIView()
        
        let label = UILabel()
        label.text = title
        label.font = .systemFont(ofSize: 15, weight: .semibold)
        label.translatesAutoresizingMaskIntoConstraints = false
        
        container.addSubview(label)
        container.addSubview(view)
        
        NSLayoutConstraint.activate([
            label.topAnchor.constraint(equalTo: container.topAnchor),
            label.leadingAnchor.constraint(equalTo: container.leadingAnchor),
            label.trailingAnchor.constraint(equalTo: container.trailingAnchor),
            
            view.topAnchor.constraint(equalTo: label.bottomAnchor, constant: 8),
            view.leadingAnchor.constraint(equalTo: container.leadingAnchor),
            view.trailingAnchor.constraint(equalTo: container.trailingAnchor),
            view.bottomAnchor.constraint(equalTo: container.bottomAnchor)
        ])
        
        return container
    }
    
    private func setupActions() {
        startButton.addTarget(self, action: #selector(toggleCapture), for: .touchUpInside)
        processModeSegment.addTarget(self, action: #selector(processModeChanged), for: .valueChanged)
    }
    
    @objc private func processModeChanged() {
        // åœ¨ä¸»çº¿ç¨‹æ›´æ–°å¤„ç†æ¨¡å¼
        currentProcessMode = processModeSegment.selectedSegmentIndex
    }
    
    // MARK: - Camera Permission
    
    private func requestCameraPermission() {
        AVCaptureDevice.requestAccess(for: .video) { granted in
            if !granted {
                self.showAlert(title: "ç›¸æœºæƒé™", message: "è¯·åœ¨è®¾ç½®ä¸­å¼€å¯ç›¸æœºæƒé™")
            }
        }
    }
    
    // MARK: - Actions
    
    @objc private func toggleCapture() {
        if captureSession?.isRunning == true {
            // åœ¨åå°çº¿ç¨‹åœæ­¢session
            DispatchQueue.global(qos: .userInitiated).async { [weak self] in
                self?.captureSession?.stopRunning()
                
                // æ›´æ–°UIéœ€è¦å›åˆ°ä¸»çº¿ç¨‹
                DispatchQueue.main.async {
                    self?.startButton.setTitle("å¼€å§‹å¤„ç†", for: .normal)
                    self?.startButton.backgroundColor = .systemBlue
                }
            }
        } else {
            if captureSession == nil {
                setupCaptureSession()
            }
            
            // åœ¨åå°çº¿ç¨‹å¯åŠ¨session
            DispatchQueue.global(qos: .userInitiated).async { [weak self] in
                self?.captureSession?.startRunning()
                
                // æ›´æ–°UIéœ€è¦å›åˆ°ä¸»çº¿ç¨‹
                DispatchQueue.main.async {
                    self?.startButton.setTitle("åœæ­¢å¤„ç†", for: .normal)
                    self?.startButton.backgroundColor = .systemRed
                }
            }
        }
    }
    
    // MARK: - Capture Setup
    
    private func setupCaptureSession() {
        captureSession = AVCaptureSession()
        captureSession?.sessionPreset = .vga640x480
        
        guard let camera = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .front),
              let input = try? AVCaptureDeviceInput(device: camera) else {
            showAlert(title: "é”™è¯¯", message: "æ— æ³•è®¿é—®æ‘„åƒå¤´")
            return
        }
        
        if captureSession?.canAddInput(input) == true {
            captureSession?.addInput(input)
        }
        
        videoOutput = AVCaptureVideoDataOutput()
        // ä½¿ç”¨ BGRA æ ¼å¼ï¼Œæ¯ä¸ªåƒç´ 4å­—èŠ‚
        videoOutput?.videoSettings = [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA
        ]
        
        let queue = DispatchQueue(label: "com.audiovideo.pixelbuffer")
        videoOutput?.setSampleBufferDelegate(self, queue: queue)
        
        if let output = videoOutput, captureSession?.canAddOutput(output) == true {
            captureSession?.addOutput(output)
        }
    }
    
    // MARK: - Pixel Buffer Processing
    
    /// å°†CVPixelBufferè½¬ä¸ºç°åº¦
    private func convertToGrayscale(_ pixelBuffer: CVPixelBuffer) -> CVPixelBuffer? {
        let width = CVPixelBufferGetWidth(pixelBuffer)
        let height = CVPixelBufferGetHeight(pixelBuffer)
        
        // åˆ›å»ºè¾“å‡ºç¼“å†²åŒº
        var outputPixelBuffer: CVPixelBuffer?
        let options: [String: Any] = [
            kCVPixelBufferCGImageCompatibilityKey as String: true,
            kCVPixelBufferCGBitmapContextCompatibilityKey as String: true
        ]
        
        CVPixelBufferCreate(kCFAllocatorDefault, width, height,
                           kCVPixelFormatType_32BGRA, options as CFDictionary,
                           &outputPixelBuffer)
        
        guard let output = outputPixelBuffer else { return nil }
        
        // é”å®šåƒç´ ç¼“å†²åŒº
        CVPixelBufferLockBaseAddress(pixelBuffer, .readOnly)
        CVPixelBufferLockBaseAddress(output, [])
        
        defer {
            CVPixelBufferUnlockBaseAddress(pixelBuffer, .readOnly)
            CVPixelBufferUnlockBaseAddress(output, [])
        }
        
        guard let srcData = CVPixelBufferGetBaseAddress(pixelBuffer),
              let dstData = CVPixelBufferGetBaseAddress(output) else {
            return nil
        }
        
        let bytesPerRow = CVPixelBufferGetBytesPerRow(pixelBuffer)
        
        // é€åƒç´ å¤„ç†ï¼šBGRAæ ¼å¼
        for y in 0..<height {
            for x in 0..<width {
                let offset = y * bytesPerRow + x * 4
                let srcPtr = srcData.advanced(by: offset).assumingMemoryBound(to: UInt8.self)
                let dstPtr = dstData.advanced(by: offset).assumingMemoryBound(to: UInt8.self)
                
                let b = Float(srcPtr[0])
                let g = Float(srcPtr[1])
                let r = Float(srcPtr[2])
                
                // ç°åº¦å…¬å¼: 0.299*R + 0.587*G + 0.114*B
                let gray = UInt8(0.114 * b + 0.587 * g + 0.299 * r)
                
                dstPtr[0] = gray
                dstPtr[1] = gray
                dstPtr[2] = gray
                dstPtr[3] = srcPtr[3] // alpha
            }
        }
        
        return output
    }
    
    /// åè‰²æ•ˆæœ
    private func invertColors(_ pixelBuffer: CVPixelBuffer) -> CVPixelBuffer? {
        let width = CVPixelBufferGetWidth(pixelBuffer)
        let height = CVPixelBufferGetHeight(pixelBuffer)
        
        var outputPixelBuffer: CVPixelBuffer?
        let options: [String: Any] = [
            kCVPixelBufferCGImageCompatibilityKey as String: true,
            kCVPixelBufferCGBitmapContextCompatibilityKey as String: true
        ]
        
        CVPixelBufferCreate(kCFAllocatorDefault, width, height,
                           kCVPixelFormatType_32BGRA, options as CFDictionary,
                           &outputPixelBuffer)
        
        guard let output = outputPixelBuffer else { return nil }
        
        CVPixelBufferLockBaseAddress(pixelBuffer, .readOnly)
        CVPixelBufferLockBaseAddress(output, [])
        
        defer {
            CVPixelBufferUnlockBaseAddress(pixelBuffer, .readOnly)
            CVPixelBufferUnlockBaseAddress(output, [])
        }
        
        guard let srcData = CVPixelBufferGetBaseAddress(pixelBuffer),
              let dstData = CVPixelBufferGetBaseAddress(output) else {
            return nil
        }
        
        let bytesPerRow = CVPixelBufferGetBytesPerRow(pixelBuffer)
        
        for y in 0..<height {
            for x in 0..<width {
                let offset = y * bytesPerRow + x * 4
                let srcPtr = srcData.advanced(by: offset).assumingMemoryBound(to: UInt8.self)
                let dstPtr = dstData.advanced(by: offset).assumingMemoryBound(to: UInt8.self)
                
                dstPtr[0] = 255 - srcPtr[0] // B
                dstPtr[1] = 255 - srcPtr[1] // G
                dstPtr[2] = 255 - srcPtr[2] // R
                dstPtr[3] = srcPtr[3]         // A
            }
        }
        
        return output
    }
    
    /// è°ƒæ•´äº®åº¦
    private func adjustBrightness(_ pixelBuffer: CVPixelBuffer, delta: Int = 50) -> CVPixelBuffer? {
        let width = CVPixelBufferGetWidth(pixelBuffer)
        let height = CVPixelBufferGetHeight(pixelBuffer)
        
        var outputPixelBuffer: CVPixelBuffer?
        let options: [String: Any] = [
            kCVPixelBufferCGImageCompatibilityKey as String: true,
            kCVPixelBufferCGBitmapContextCompatibilityKey as String: true
        ]
        
        CVPixelBufferCreate(kCFAllocatorDefault, width, height,
                           kCVPixelFormatType_32BGRA, options as CFDictionary,
                           &outputPixelBuffer)
        
        guard let output = outputPixelBuffer else { return nil }
        
        CVPixelBufferLockBaseAddress(pixelBuffer, .readOnly)
        CVPixelBufferLockBaseAddress(output, [])
        
        defer {
            CVPixelBufferUnlockBaseAddress(pixelBuffer, .readOnly)
            CVPixelBufferUnlockBaseAddress(output, [])
        }
        
        guard let srcData = CVPixelBufferGetBaseAddress(pixelBuffer),
              let dstData = CVPixelBufferGetBaseAddress(output) else {
            return nil
        }
        
        let bytesPerRow = CVPixelBufferGetBytesPerRow(pixelBuffer)
        
        for y in 0..<height {
            for x in 0..<width {
                let offset = y * bytesPerRow + x * 4
                let srcPtr = srcData.advanced(by: offset).assumingMemoryBound(to: UInt8.self)
                let dstPtr = dstData.advanced(by: offset).assumingMemoryBound(to: UInt8.self)
                
                dstPtr[0] = UInt8(max(0, min(255, Int(srcPtr[0]) + delta)))
                dstPtr[1] = UInt8(max(0, min(255, Int(srcPtr[1]) + delta)))
                dstPtr[2] = UInt8(max(0, min(255, Int(srcPtr[2]) + delta)))
                dstPtr[3] = srcPtr[3]
            }
        }
        
        return output
    }
    
    /// è¯»å–ä¸­å¿ƒåƒç´ ä¿¡æ¯
    private func readPixelInfo(_ pixelBuffer: CVPixelBuffer) -> String {
        let width = CVPixelBufferGetWidth(pixelBuffer)
        let height = CVPixelBufferGetHeight(pixelBuffer)
        
        CVPixelBufferLockBaseAddress(pixelBuffer, .readOnly)
        defer { CVPixelBufferUnlockBaseAddress(pixelBuffer, .readOnly) }
        
        guard let data = CVPixelBufferGetBaseAddress(pixelBuffer) else {
            return "æ— æ³•è¯»å–åƒç´ æ•°æ®"
        }
        
        let bytesPerRow = CVPixelBufferGetBytesPerRow(pixelBuffer)
        let centerX = width / 2
        let centerY = height / 2
        let offset = centerY * bytesPerRow + centerX * 4
        let ptr = data.advanced(by: offset).assumingMemoryBound(to: UInt8.self)
        
        let b = ptr[0]
        let g = ptr[1]
        let r = ptr[2]
        let a = ptr[3]
        
        var info = "ä¸­å¿ƒåƒç´  (\(centerX), \(centerY)):\n"
        info += "R: \(r), G: \(g), B: \(b), A: \(a)\n"
        info += "Hex: #\(String(format: "%02X%02X%02X", r, g, b))\n"
        info += "\nç¼“å†²åŒºä¿¡æ¯:\n"
        info += "å°ºå¯¸: \(width) x \(height)\n"
        info += "æ¯è¡Œå­—èŠ‚: \(bytesPerRow)\n"
        info += "åƒç´ æ ¼å¼: BGRA (32bit)\n"
        info += "æ•°æ®å¤§å°: \(formatBytes(CVPixelBufferGetDataSize(pixelBuffer)))"
        
        return info
    }
    
    // MARK: - Helper Methods
    
    private func pixelBufferToUIImage(_ pixelBuffer: CVPixelBuffer) -> UIImage? {
        let ciImage = CIImage(cvPixelBuffer: pixelBuffer)
        let context = CIContext()
        
        guard let cgImage = context.createCGImage(ciImage, from: ciImage.extent) else {
            return nil
        }
        
        return UIImage(cgImage: cgImage)
    }
    
    private func formatBytes(_ bytes: Int) -> String {
        let formatter = ByteCountFormatter()
        formatter.countStyle = .binary
        return formatter.string(fromByteCount: Int64(bytes))
    }
    
    private func showAlert(title: String, message: String) {
        DispatchQueue.main.async {
            let alert = UIAlertController(title: title, message: message, preferredStyle: .alert)
            alert.addAction(UIAlertAction(title: "ç¡®å®š", style: .default))
            self.present(alert, animated: true)
        }
    }
}

// MARK: - AVCaptureVideoDataOutputSampleBufferDelegate

extension CVPixelBufferViewController: AVCaptureVideoDataOutputSampleBufferDelegate {
    func captureOutput(_ output: AVCaptureOutput,
                      didOutput sampleBuffer: CMSampleBuffer,
                      from connection: AVCaptureConnection) {
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }
        
        // âœ… ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„å±æ€§ï¼Œè€Œä¸æ˜¯ç›´æ¥è®¿é—®UIæ§ä»¶
        let mode = currentProcessMode
        
        // æ ¹æ®é€‰æ‹©çš„æ¨¡å¼å¤„ç†åƒç´ 
        let processedBuffer: CVPixelBuffer?
        var info = ""
        
        switch mode {
        case 0: // ç°åº¦
            processedBuffer = convertToGrayscale(pixelBuffer)
            info = "ç°åº¦è½¬æ¢ï¼šä½¿ç”¨å…¬å¼ 0.299*R + 0.587*G + 0.114*B"
        case 1: // åè‰²
            processedBuffer = invertColors(pixelBuffer)
            info = "åè‰²æ•ˆæœï¼š255 - åŸå§‹å€¼"
        case 2: // äº®åº¦
            processedBuffer = adjustBrightness(pixelBuffer, delta: 50)
            info = "äº®åº¦å¢å¼ºï¼šæ¯ä¸ªé€šé“ +50"
        case 3: // åƒç´ è¯»å–
            processedBuffer = pixelBuffer
            info = readPixelInfo(pixelBuffer)
        default:
            processedBuffer = nil
        }
        
        // æ›´æ–°UI
        DispatchQueue.main.async { [weak self] in
            if let originalImage = self?.pixelBufferToUIImage(pixelBuffer) {
                self?.originalImageView.image = originalImage
            }
            
            if let processed = processedBuffer,
               let processedImage = self?.pixelBufferToUIImage(processed) {
                self?.processedImageView.image = processedImage
            }
            
            self?.infoLabel.text = info
        }
    }
}

