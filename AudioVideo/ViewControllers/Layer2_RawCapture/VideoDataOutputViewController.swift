//
//  VideoDataOutputViewController.swift
//  AudioVideo
//
//  Layer 2: åŸå§‹æ•°æ®é‡‡é›†ä¸å¤„ç†
//  AVCaptureVideoDataOutput - å®æ—¶è·å–åŸå§‹è§†é¢‘å¸§
//

import UIKit
import AVFoundation

class VideoDataOutputViewController: UIViewController {
    
    // MARK: - Properties
    
    private var captureSession: AVCaptureSession?
    private var videoDataOutput: AVCaptureVideoDataOutput?
    private var previewLayer: AVCaptureVideoPreviewLayer?
    
    private var frameCount: Int = 0
    private var startTime: CFAbsoluteTime = 0
    private var droppedFrames: Int = 0
    
    private let previewView: UIView = {
        let view = UIView()
        view.backgroundColor = .black
        view.layer.cornerRadius = 8
        view.clipsToBounds = true
        view.translatesAutoresizingMaskIntoConstraints = false
        return view
    }()
    
    private let statsLabel: UILabel = {
        let label = UILabel()
        label.numberOfLines = 0
        label.font = .monospacedSystemFont(ofSize: 12, weight: .medium)
        label.textAlignment = .left
        label.textColor = .label
        label.backgroundColor = .systemBackground.withAlphaComponent(0.9)
        label.layer.cornerRadius = 8
        label.clipsToBounds = true
        label.translatesAutoresizingMaskIntoConstraints = false
        return label
    }()
    
    private let controlPanel: UIView = {
        let view = UIView()
        view.backgroundColor = .secondarySystemBackground
        view.layer.cornerRadius = 12
        view.translatesAutoresizingMaskIntoConstraints = false
        return view
    }()
    
    private let startButton: UIButton = {
        let button = UIButton(type: .system)
        button.setTitle("å¼€å§‹é‡‡é›†", for: .normal)
        button.backgroundColor = .systemGreen
        button.setTitleColor(.white, for: .normal)
        button.layer.cornerRadius = 8
        button.translatesAutoresizingMaskIntoConstraints = false
        return button
    }()
    
    private let fpsSegment: UISegmentedControl = {
        let items = ["15fps", "30fps", "60fps"]
        let segment = UISegmentedControl(items: items)
        segment.selectedSegmentIndex = 1
        segment.translatesAutoresizingMaskIntoConstraints = false
        return segment
    }()
    
    private let formatSegment: UISegmentedControl = {
        let items = ["BGRA", "YUV"]
        let segment = UISegmentedControl(items: items)
        segment.selectedSegmentIndex = 0
        segment.translatesAutoresizingMaskIntoConstraints = false
        return segment
    }()
    
    private let scrollView: UIScrollView = {
        let scroll = UIScrollView()
        scroll.translatesAutoresizingMaskIntoConstraints = false
        return scroll
    }()
    
    private let contentView: UIView = {
        let view = UIView()
        view.translatesAutoresizingMaskIntoConstraints = false
        return view
    }()
    
    private let descriptionLabel: UILabel = {
        let label = UILabel()
        label.numberOfLines = 0
        label.font = .systemFont(ofSize: 14)
        label.textColor = .secondaryLabel
        label.text = """
        ğŸ“¹ AVCaptureVideoDataOutput è¯¦è§£
        
        è¿™æ˜¯è·å–åŸå§‹è§†é¢‘å¸§æœ€æ ¸å¿ƒçš„æ–¹å¼ï¼Œç›¸æ¯”AVCaptureMovieFileOutputï¼Œå®ƒæä¾›ï¼š
        
        âœ… é€å¸§è®¿é—®ï¼šæ¯ä¸€å¸§éƒ½é€šè¿‡å›è°ƒä¼ é€’
        âœ… å®æ—¶å¤„ç†ï¼šå¯ä»¥åœ¨å›è°ƒä¸­ç›´æ¥å¤„ç†åƒç´ æ•°æ®
        âœ… æ ¼å¼æ§åˆ¶ï¼šç²¾ç¡®æ§åˆ¶åƒç´ æ ¼å¼
        âœ… å¸§ç‡æ§åˆ¶ï¼šè®¾ç½®æœ€å°/æœ€å¤§å¸§é—´éš”
        
        å…³é”®é…ç½®ï¼š
        â€¢ videoSettings: æŒ‡å®šè¾“å‡ºçš„åƒç´ æ ¼å¼
        â€¢ alwaysDiscardsLateVideoFrames: æ˜¯å¦ä¸¢å¼ƒå»¶è¿Ÿå¸§
        â€¢ setSampleBufferDelegate: è®¾ç½®å¸§å›è°ƒ
        
        é€‚ç”¨åœºæ™¯ï¼š
        â€¢ å®æ—¶æ»¤é•œå’Œç‰¹æ•ˆ
        â€¢ äººè„¸è¯†åˆ«ã€ç›®æ ‡æ£€æµ‹
        â€¢ è‡ªå®šä¹‰ç¼–ç å™¨
        â€¢ å¸§çº§åˆ«çš„ç²¾ç¡®æ§åˆ¶
        """
        label.translatesAutoresizingMaskIntoConstraints = false
        return label
    }()
    
    // MARK: - Lifecycle
    
    override func viewDidLoad() {
        super.viewDidLoad()
        setupUI()
        setupActions()
        requestCameraPermission()
    }
    
    override func viewDidLayoutSubviews() {
        super.viewDidLayoutSubviews()
        previewLayer?.frame = previewView.bounds
    }
    
    deinit {
        captureSession?.stopRunning()
    }
    
    // MARK: - Setup
    
    private func setupUI() {
        view.backgroundColor = .systemBackground
        
        view.addSubview(scrollView)
        scrollView.addSubview(contentView)
        
        contentView.addSubview(descriptionLabel)
        contentView.addSubview(controlPanel)
        controlPanel.addSubview(createLabel(text: "å¸§ç‡:"))
        controlPanel.addSubview(fpsSegment)
        controlPanel.addSubview(createLabel(text: "æ ¼å¼:"))
        controlPanel.addSubview(formatSegment)
        controlPanel.addSubview(startButton)
        contentView.addSubview(previewView)
        contentView.addSubview(statsLabel)
        
        NSLayoutConstraint.activate([
            scrollView.topAnchor.constraint(equalTo: view.safeAreaLayoutGuide.topAnchor),
            scrollView.leadingAnchor.constraint(equalTo: view.leadingAnchor),
            scrollView.trailingAnchor.constraint(equalTo: view.trailingAnchor),
            scrollView.bottomAnchor.constraint(equalTo: view.bottomAnchor),
            
            contentView.topAnchor.constraint(equalTo: scrollView.topAnchor),
            contentView.leadingAnchor.constraint(equalTo: scrollView.leadingAnchor),
            contentView.trailingAnchor.constraint(equalTo: scrollView.trailingAnchor),
            contentView.bottomAnchor.constraint(equalTo: scrollView.bottomAnchor),
            contentView.widthAnchor.constraint(equalTo: scrollView.widthAnchor),
            
            descriptionLabel.topAnchor.constraint(equalTo: contentView.topAnchor, constant: 16),
            descriptionLabel.leadingAnchor.constraint(equalTo: contentView.leadingAnchor, constant: 16),
            descriptionLabel.trailingAnchor.constraint(equalTo: contentView.trailingAnchor, constant: -16),
            
            controlPanel.topAnchor.constraint(equalTo: descriptionLabel.bottomAnchor, constant: 16),
            controlPanel.leadingAnchor.constraint(equalTo: contentView.leadingAnchor, constant: 16),
            controlPanel.trailingAnchor.constraint(equalTo: contentView.trailingAnchor, constant: -16),
            controlPanel.heightAnchor.constraint(equalToConstant: 160),
            
            previewView.topAnchor.constraint(equalTo: controlPanel.bottomAnchor, constant: 16),
            previewView.leadingAnchor.constraint(equalTo: contentView.leadingAnchor, constant: 16),
            previewView.trailingAnchor.constraint(equalTo: contentView.trailingAnchor, constant: -16),
            previewView.heightAnchor.constraint(equalTo: previewView.widthAnchor, multiplier: 4.0/3.0),
            
            statsLabel.topAnchor.constraint(equalTo: previewView.bottomAnchor, constant: 16),
            statsLabel.leadingAnchor.constraint(equalTo: contentView.leadingAnchor, constant: 16),
            statsLabel.trailingAnchor.constraint(equalTo: contentView.trailingAnchor, constant: -16),
            statsLabel.bottomAnchor.constraint(equalTo: contentView.bottomAnchor, constant: -16)
        ])
        
        setupControlPanelLayout()
    }
    
    private func setupControlPanelLayout() {
        guard let fpsLabel = controlPanel.subviews[0] as? UILabel,
              let formatLabel = controlPanel.subviews[2] as? UILabel else { return }
        
        NSLayoutConstraint.activate([
            fpsLabel.topAnchor.constraint(equalTo: controlPanel.topAnchor, constant: 16),
            fpsLabel.leadingAnchor.constraint(equalTo: controlPanel.leadingAnchor, constant: 16),
            
            fpsSegment.centerYAnchor.constraint(equalTo: fpsLabel.centerYAnchor),
            fpsSegment.leadingAnchor.constraint(equalTo: fpsLabel.trailingAnchor, constant: 12),
            fpsSegment.trailingAnchor.constraint(equalTo: controlPanel.trailingAnchor, constant: -16),
            
            formatLabel.topAnchor.constraint(equalTo: fpsLabel.bottomAnchor, constant: 16),
            formatLabel.leadingAnchor.constraint(equalTo: controlPanel.leadingAnchor, constant: 16),
            
            formatSegment.centerYAnchor.constraint(equalTo: formatLabel.centerYAnchor),
            formatSegment.leadingAnchor.constraint(equalTo: formatLabel.trailingAnchor, constant: 12),
            formatSegment.trailingAnchor.constraint(equalTo: controlPanel.trailingAnchor, constant: -16),
            
            startButton.topAnchor.constraint(equalTo: formatLabel.bottomAnchor, constant: 16),
            startButton.centerXAnchor.constraint(equalTo: controlPanel.centerXAnchor),
            startButton.widthAnchor.constraint(equalToConstant: 120),
            startButton.heightAnchor.constraint(equalToConstant: 44)
        ])
    }
    
    private func createLabel(text: String) -> UILabel {
        let label = UILabel()
        label.text = text
        label.font = .systemFont(ofSize: 15, weight: .semibold)
        label.translatesAutoresizingMaskIntoConstraints = false
        return label
    }
    
    private func setupActions() {
        startButton.addTarget(self, action: #selector(toggleCapture), for: .touchUpInside)
    }
    
    // MARK: - Camera Permission
    
    private func requestCameraPermission() {
        AVCaptureDevice.requestAccess(for: .video) { granted in
            if !granted {
                self.showAlert(title: "ç›¸æœºæƒé™", message: "è¯·åœ¨è®¾ç½®ä¸­å¼€å¯ç›¸æœºæƒé™")
            }
        }
    }
    
    // MARK: - Actions
    
    @objc private func toggleCapture() {
        if captureSession?.isRunning == true {
            captureSession?.stopRunning()
            startButton.setTitle("å¼€å§‹é‡‡é›†", for: .normal)
            startButton.backgroundColor = .systemGreen
        } else {
            setupCaptureSession()
            captureSession?.startRunning()
            startButton.setTitle("åœæ­¢é‡‡é›†", for: .normal)
            startButton.backgroundColor = .systemRed
            
            frameCount = 0
            droppedFrames = 0
            startTime = CFAbsoluteTimeGetCurrent()
        }
    }
    
    // MARK: - Capture Setup
    
    private func setupCaptureSession() {
        // åœæ­¢æ—§çš„session
        captureSession?.stopRunning()
        previewLayer?.removeFromSuperlayer()
        
        captureSession = AVCaptureSession()
        
        // è®¾ç½®åˆ†è¾¨ç‡
        captureSession?.sessionPreset = .vga640x480
        
        // æ‘„åƒå¤´è¾“å…¥
        guard let camera = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .front),
              let input = try? AVCaptureDeviceInput(device: camera) else {
            showAlert(title: "é”™è¯¯", message: "æ— æ³•è®¿é—®æ‘„åƒå¤´")
            return
        }
        
        if captureSession?.canAddInput(input) == true {
            captureSession?.addInput(input)
        }
        
        // è®¾ç½®å¸§ç‡
        let fps = [15, 30, 60][fpsSegment.selectedSegmentIndex]
        try? camera.lockForConfiguration()
        camera.activeVideoMinFrameDuration = CMTime(value: 1, timescale: CMTimeScale(fps))
        camera.activeVideoMaxFrameDuration = CMTime(value: 1, timescale: CMTimeScale(fps))
        camera.unlockForConfiguration()
        
        // é…ç½®VideoDataOutput
        videoDataOutput = AVCaptureVideoDataOutput()
        
        // è®¾ç½®åƒç´ æ ¼å¼
        let pixelFormat: OSType
        if formatSegment.selectedSegmentIndex == 0 {
            pixelFormat = kCVPixelFormatType_32BGRA
        } else {
            pixelFormat = kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange
        }
        
        videoDataOutput?.videoSettings = [
            kCVPixelBufferPixelFormatTypeKey as String: pixelFormat
        ]
        
        // æ˜¯å¦ä¸¢å¼ƒå»¶è¿Ÿå¸§ï¼ˆæ€§èƒ½å…³é”®è®¾ç½®ï¼‰
        videoDataOutput?.alwaysDiscardsLateVideoFrames = true
        
        // è®¾ç½®ä»£ç†é˜Ÿåˆ—
        let queue = DispatchQueue(label: "com.audiovideo.videodata", qos: .userInitiated)
        videoDataOutput?.setSampleBufferDelegate(self, queue: queue)
        
        if let output = videoDataOutput, captureSession?.canAddOutput(output) == true {
            captureSession?.addOutput(output)
        }
        
        // è®¾ç½®è§†é¢‘æ–¹å‘
        if let connection = videoDataOutput?.connection(with: .video) {
            if connection.isVideoOrientationSupported {
                connection.videoOrientation = .portrait
            }
            if connection.isVideoMirroringSupported {
                connection.isVideoMirrored = true
            }
        }
        
        // é¢„è§ˆå›¾å±‚
        let preview = AVCaptureVideoPreviewLayer(session: captureSession!)
        preview.videoGravity = .resizeAspectFill
        preview.frame = previewView.bounds
        previewView.layer.addSublayer(preview)
        previewLayer = preview
    }
    
    // MARK: - Frame Analysis
    
    private func analyzeFrame(_ sampleBuffer: CMSampleBuffer) -> String {
        frameCount += 1
        let elapsed = CFAbsoluteTimeGetCurrent() - startTime
        let actualFPS = Double(frameCount) / elapsed
        
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {
            return "æ— æ³•è·å–åƒç´ æ•°æ®"
        }
        
        let width = CVPixelBufferGetWidth(pixelBuffer)
        let height = CVPixelBufferGetHeight(pixelBuffer)
        let pixelFormat = CVPixelBufferGetPixelFormatType(pixelBuffer)
        let dataSize = CVPixelBufferGetDataSize(pixelBuffer)
        let planeCount = CVPixelBufferGetPlaneCount(pixelBuffer)
        
        let presentationTime = CMSampleBufferGetPresentationTimeStamp(sampleBuffer)
        let duration = CMSampleBufferGetDuration(sampleBuffer)
        
        var info = "ğŸ“Š å®æ—¶ç»Ÿè®¡\n\n"
        info += "æ€§èƒ½æŒ‡æ ‡:\n"
        info += "  â€¢ å·²å¤„ç†å¸§æ•°: \(frameCount)\n"
        info += "  â€¢ ç›®æ ‡FPS: \([15, 30, 60][fpsSegment.selectedSegmentIndex])\n"
        info += "  â€¢ å®é™…FPS: \(String(format: "%.1f", actualFPS))\n"
        info += "  â€¢ ä¸¢å¸§æ•°: \(droppedFrames)\n"
        info += "  â€¢ è¿è¡Œæ—¶é—´: \(String(format: "%.1f", elapsed))s\n\n"
        
        info += "å¸§ä¿¡æ¯:\n"
        info += "  â€¢ åˆ†è¾¨ç‡: \(width) x \(height)\n"
        info += "  â€¢ åƒç´ æ ¼å¼: \(fourCCToString(pixelFormat))\n"
        info += "  â€¢ æ•°æ®å¤§å°: \(formatBytes(dataSize))\n"
        info += "  â€¢ å¹³é¢æ•°: \(planeCount)\n\n"
        
        info += "æ—¶é—´ä¿¡æ¯:\n"
        info += "  â€¢ PTS: \(String(format: "%.3f", presentationTime.seconds))s\n"
        if duration.isValid {
            info += "  â€¢ Duration: \(String(format: "%.4f", duration.seconds))s\n"
            info += "  â€¢ Expected FPS: \(String(format: "%.1f", 1.0/duration.seconds))\n"
        }
        
        info += "\n"
        
        if planeCount > 0 {
            info += "å¹³é¢è¯¦æƒ…:\n"
            for i in 0..<planeCount {
                let planeWidth = CVPixelBufferGetWidthOfPlane(pixelBuffer, i)
                let planeHeight = CVPixelBufferGetHeightOfPlane(pixelBuffer, i)
                let planeBytesPerRow = CVPixelBufferGetBytesPerRowOfPlane(pixelBuffer, i)
                info += "  Plane \(i): \(planeWidth)x\(planeHeight), \(planeBytesPerRow) B/row\n"
            }
        }
        
        return info
    }
    
    // MARK: - Helper Methods
    
    private func fourCCToString(_ value: FourCharCode) -> String {
        let chars = [
            Character(UnicodeScalar((value >> 24) & 0xFF)!),
            Character(UnicodeScalar((value >> 16) & 0xFF)!),
            Character(UnicodeScalar((value >> 8) & 0xFF)!),
            Character(UnicodeScalar(value & 0xFF)!)
        ]
        return String(chars)
    }
    
    private func formatBytes(_ bytes: Int) -> String {
        let formatter = ByteCountFormatter()
        formatter.countStyle = .binary
        return formatter.string(fromByteCount: Int64(bytes))
    }
    
    private func showAlert(title: String, message: String) {
        DispatchQueue.main.async {
            let alert = UIAlertController(title: title, message: message, preferredStyle: .alert)
            alert.addAction(UIAlertAction(title: "ç¡®å®š", style: .default))
            self.present(alert, animated: true)
        }
    }
}

// MARK: - AVCaptureVideoDataOutputSampleBufferDelegate

extension VideoDataOutputViewController: AVCaptureVideoDataOutputSampleBufferDelegate {
    func captureOutput(_ output: AVCaptureOutput,
                      didOutput sampleBuffer: CMSampleBuffer,
                      from connection: AVCaptureConnection) {
        // è¿™é‡Œæ¯ä¸€å¸§éƒ½ä¼šå›è°ƒ
        // å¯ä»¥åœ¨è¿™é‡Œè¿›è¡Œå®æ—¶å¤„ç†ï¼šæ»¤é•œã€è¯†åˆ«ã€ç¼–ç ç­‰
        
        let info = analyzeFrame(sampleBuffer)
        
        // é™åˆ¶æ›´æ–°é¢‘ç‡ï¼Œæ¯ç§’æ›´æ–°5æ¬¡
        if frameCount % 6 == 0 {
            DispatchQueue.main.async { [weak self] in
                self?.statsLabel.text = info
            }
        }
    }
    
    func captureOutput(_ output: AVCaptureOutput,
                      didDrop sampleBuffer: CMSampleBuffer,
                      from connection: AVCaptureConnection) {
        // å½“å¤„ç†é€Ÿåº¦è·Ÿä¸ä¸Šæ—¶ï¼Œè¿™é‡Œä¼šè¢«è°ƒç”¨
        droppedFrames += 1
        print("âš ï¸ ä¸¢å¼ƒä¸€å¸§ - æ€»ä¸¢å¸§æ•°: \(droppedFrames)")
    }
}

